{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile\n",
    "from scipy.fft import fft, ifft\n",
    "from scipy import fftpack\n",
    "from scipy import signal\n",
    "import soundfile as sf\n",
    "from os.path import basename\n",
    "from skimage import io\n",
    "from tensorflow.keras.preprocessing.image import load_img,img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_directory = 'Healthy2006-wav/'\n",
    "SIZE = 500\n",
    "dataset = {}\n",
    "\n",
    "my_audios = os.listdir(audio_directory)\n",
    "for i, audio_name in enumerate(my_audios):\n",
    "    if (audio_name.split('.')[1] == 'wav'):\n",
    "            audio,sr = librosa.load(audio_directory+audio_name)\n",
    "            dataset[audio_name] = audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spectrogram(Y, sr, hop_length, y_axis=\"linear\"):\n",
    "    plt.figure(figsize=(25, 10))\n",
    "    librosa.display.specshow(Y, \n",
    "                             sr=sr, \n",
    "                             hop_length=hop_length, \n",
    "                             x_axis=\"time\", \n",
    "                             y_axis=y_axis)\n",
    "    plt.colorbar(format=\"%+2.f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-9-b12ecacc36d0>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-9-b12ecacc36d0>\"\u001b[1;36m, line \u001b[1;32m6\u001b[0m\n\u001b[1;33m    frequences = fftpack.fftfreq(scale.size)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def transformation(name,scale):\n",
    "# création des variables Fourier et Fréquences, qui permettent de construire le spectre du signal.\n",
    "    fourier = fftpack.fft(scale)\n",
    "    power = np.abs(fourier\n",
    "# la variable power est créée pour éiminer les amplitudes négatives\n",
    "    frequences = fftpack.fftfreq(scale.size)\n",
    "\n",
    "# filtre du spectre avec du boolean indexing de Numpy\n",
    "    fourier[ power < np.percentile(power,90) ] = 0\n",
    "# Transformation de Fourier Inverse: genere un nouveau signal temporel depuis le spectre filtré\n",
    "    filtered_signal = fftpack.ifft(fourier)\n",
    "\n",
    "    FRAME_SIZE = 2048\n",
    "    HOP_SIZE = 512\n",
    "\n",
    "    S_scale = librosa.stft(np.abs(filtered_signal), n_fft=FRAME_SIZE, hop_length=HOP_SIZE) #librosa.stft(scale, n_fft=FRAME_SIZE, hop_length=HOP_SIZE)\n",
    "    Y_scale = np.abs(S_scale) ** 2\n",
    "\n",
    "    Y_log_scale = librosa.power_to_db(Y_scale)\n",
    "\n",
    "    plot_spectrogram(Y_log_scale, sr, HOP_SIZE, y_axis=\"log\")\n",
    "    fileName1, fileExtension = os.path.splitext(name)\n",
    "    fileName1 = str(fileName1) + \".png\"\n",
    "    plt.savefig('spectro_healthy/'+fileName1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-d7075440fc31>:2: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure(figsize=(25, 10))\n"
     ]
    }
   ],
   "source": [
    "for cle,valeur in dataset.items():\n",
    "    transformation(cle,valeur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
